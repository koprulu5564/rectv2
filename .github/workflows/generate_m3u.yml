name: Generate and Update M3U Playlist

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *' # Her gün saat 00:00'da çalışır

env:
  MAIN_URL: "https://m.prectv50.sbs"
  SW_KEY: "4F5A9C3D9A86FA54EACEDDD635185/c3c5bd17-e37b-4b94-a944-8a3688a30452"

jobs:
  generate-m3u:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests tqdm
        
    - name: Generate M3U playlist
      run: |
        cat << 'EOF' > generate_playlist.py
        import requests
        import datetime
        import os
        from tqdm import tqdm
        from concurrent.futures import ThreadPoolExecutor, as_completed

        # Configuration
        MAIN_URL = os.environ.get('MAIN_URL')
        SW_KEY = os.environ.get('SW_KEY')
        
        HEADERS = {
            "User-Agent": "okhttp/4.12.0",
            "Referer": "https://twitter.com/"
        }

        def fetch_url(url):
            """URL'den veri çekme fonksiyonu"""
            try:
                response = requests.get(url, headers=HEADERS, timeout=10)
                if response.status_code == 404:
                    return None
                response.raise_for_status()
                return response.json()
            except Exception as e:
                print(f"Error fetching {url}: {e}")
                return None

        def get_all_paginated_data(base_url, category_name):
            """Tüm sayfaları tarayarak veri toplar"""
            print(f"\nFetching {category_name}...")
            all_data = []
            page = 0
            
            with tqdm(desc=category_name) as pbar:
                while True:
                    url = base_url.replace("SAYFA", str(page))
                    data = fetch_url(url)
                    
                    if not data or not isinstance(data, list) or len(data) == 0:
                        break
                        
                    all_data.extend(data)
                    page += 1
                    pbar.update(1)
            
            return all_data

        def get_live_categories():
            """Canlı yayın kategorilerini getir"""
            print("\nFetching live categories...")
            categories = {
                "Ulusal Kanallar": [],
                "Spor Kanalları": [],
                "Sinema Kanalları": [],
                "Belgesel Kanalları": [],
                "Haber Kanalları": [],
                "Müzik Kanalları": [],
                "Yerel Kanallar": [],
                "Çocuk Kanalları": [],
                "Diğer Kanallar": []  # Hata çözümü: Diğer Kanallar kategorisi eklendi
            }
            
            # Tüm canlı yayınları getir
            base_url = f"{MAIN_URL}/api/channel/by/filtres/0/0/SAYFA/{SW_KEY}/"
            all_channels = get_all_paginated_data(base_url, "Canlı Yayınlar")
            
            # Kanal isimlerine göre kategorize et
            for channel in all_channels:
                if not channel.get('title') or not channel.get('sources'):
                    continue
                    
                channel_name = channel['title']
                channel_group = "Diğer Kanallar"
                
                # Kanal adına göre kategori belirle
                if any(keyword in channel_name for keyword in ["TRT", "ATV", "FOX", "Kanal D", "Show TV", "Star", "TV8"]):
                    channel_group = "Ulusal Kanallar"
                elif any(keyword in channel_name for keyword in ["Spor", "GS TV", "FB TV", "BJK TV", "Bein"]):
                    channel_group = "Spor Kanalları"
                elif any(keyword in channel_name for keyword in ["Sinema", "Film", "Dizi"]):
                    channel_group = "Sinema Kanalları"
                elif any(keyword in channel_name for keyword in ["Belgesel", "Nat Geo", "Discovery"]):
                    channel_group = "Belgesel Kanalları"
                elif any(keyword in channel_name for keyword in ["Haber", "CNN", "NTV", "HaberTürk", "TGRT"]):
                    channel_group = "Haber Kanalları"
                elif any(keyword in channel_name for keyword in ["Müzik", "Kral", "Power", "Number One"]):
                    channel_group = "Müzik Kanalları"
                elif any(keyword in channel_name for keyword in ["Çocuk", "Cartoon", "Minika", "Kidz"]):
                    channel_group = "Çocuk Kanalları"
                elif any(keyword in channel_name for keyword in ["TV", "Kanalı", "Channel"]):
                    channel_group = "Yerel Kanallar"
                
                categories[channel_group].append(channel)
            
            return categories

        def get_movies_by_category():
            """Filmleri kategorilerine göre getir"""
            movie_categories = [
                (0, "Son Eklenen Filmler"),
                (14, "Aile Filmleri"),
                (1, "Aksiyon Filmleri"),
                (13, "Animasyon Filmleri"),
                (19, "Belgeseller"),
                (4, "Bilim Kurgu Filmleri"),
                (2, "Dram Filmleri"),
                (10, "Fantastik Filmleri"),
                (3, "Komedi Filmleri"),
                (8, "Korku Filmleri"),
                (17, "Macera Filmleri"),
                (5, "Romantik Filmleri")
            ]
            
            all_movies = {}
            
            with ThreadPoolExecutor() as executor:
                futures = []
                for cat_id, cat_name in movie_categories:
                    base_url = f"{MAIN_URL}/api/movie/by/filtres/{cat_id}/created/SAYFA/{SW_KEY}/"
                    futures.append(executor.submit(get_all_paginated_data, base_url, cat_name))
                
                for future, (cat_id, cat_name) in zip(as_completed(futures), movie_categories):
                    all_movies[cat_name] = future.result()
            
            return all_movies

        def get_series_by_category():
            """Dizileri kategorilerine göre getir"""
            series_categories = [
                (0, "Son Eklenen Diziler"),
                (1, "Aksiyon Dizileri"),
                (2, "Dram Dizileri"),
                (3, "Komedi Dizileri"),
                (4, "Bilim Kurgu Dizileri"),
                (5, "Polisiye Dizileri"),
                (6, "Romantik Dizileri"),
                (7, "Tarihi Dizileri")
            ]
            
            all_series = {}
            
            with ThreadPoolExecutor() as executor:
                futures = []
                for cat_id, cat_name in series_categories:
                    base_url = f"{MAIN_URL}/api/serie/by/filtres/{cat_id}/created/SAYFA/{SW_KEY}/"
                    futures.append(executor.submit(get_all_paginated_data, base_url, cat_name))
                
                for future, (cat_id, cat_name) in zip(as_completed(futures), series_categories):
                    all_series[cat_name] = future.result()
            
            return all_series

        def get_series_episodes(series_id):
            """Dizi bölümlerini getir"""
            url = f"{MAIN_URL}/api/season/by/serie/{series_id}/{SW_KEY}/"
            data = fetch_url(url)
            return data if isinstance(data, list) else []

        def generate_m3u_playlist():
            """M3U playlist dosyası oluştur"""
            print("Starting playlist generation...")
            
            with open("playlist.m3u", "w", encoding="utf-8") as f:
                # M3U başlık bilgisi
                f.write("#EXTM3U\n")
                f.write(f"# Generated at: {datetime.datetime.now()}\n")
                f.write(f"# API Source: {MAIN_URL}\n\n")
                
                # 1. CANLI YAYINLAR (Kategorilere ayrılmış)
                live_categories = get_live_categories()
                for category_name, channels in live_categories.items():
                    if not channels:
                        continue
                        
                    f.write(f'#EXTINF:-1 group-title="CANLI - {category_name}",{category_name}\n')
                    for channel in channels:
                        channel_name = channel['title']
                        channel_image = channel.get('image', '')
                        channel_url = channel['sources'][0].get('url', '')
                        
                        if channel_url:
                            f.write(f'#EXTINF:-1 tvg-id="{channel.get("id", "")}" tvg-name="{channel_name}" tvg-logo="{channel_image}" group-title="CANLI - {category_name}",{channel_name}\n')
                            f.write(f'#EXTVLCOPT:http-user-agent=googleusercontent\n')
                            f.write(f'#EXTVLCOPT:http-referrer=https://twitter.com/\n')
                            f.write(f"{channel_url}\n\n")
                
                # 2. FİLMLER (Kategorilere ayrılmış)
                movies_by_category = get_movies_by_category()
                for category_name, movies in movies_by_category.items():
                    if not movies:
                        continue
                        
                    f.write(f'#EXTINF:-1 group-title="FİLMLER - {category_name}",{category_name}\n')
                    for movie in movies:
                        if not movie.get('sources'):
                            continue
                            
                        movie_name = movie['title']
                        movie_image = movie.get('image', '')
                        movie_url = movie['sources'][0].get('url', '')
                        
                        if movie_url:
                            f.write(f'#EXTINF:-1 tvg-id="{movie.get("id", "")}" tvg-name="{movie_name}" tvg-logo="{movie_image}" group-title="FİLMLER - {category_name}",{movie_name}\n')
                            f.write(f'#EXTVLCOPT:http-user-agent=googleusercontent\n')
                            f.write(f'#EXTVLCOPT:http-referrer=https://twitter.com/\n')
                            f.write(f"{movie_url}\n\n")
                
                # 3. DİZİLER (Kategorilere ve dizi adlarına göre ayrılmış)
                series_by_category = get_series_by_category()
                for category_name, series in series_by_category.items():
                    if not series:
                        continue
                    
                    f.write(f'#EXTINF:-1 group-title="DİZİLER - {category_name}",{category_name}\n')
                    
                    with ThreadPoolExecutor() as executor:
                        futures = []
                        for serie in series:
                            if not serie.get('id'):
                                continue
                                
                            futures.append(executor.submit(get_series_episodes, serie['id']))
                        
                        for future, serie in zip(as_completed(futures), series):
                            episodes = future.result()
                            if not episodes:
                                continue
                                
                            serie_name = serie['title']
                            serie_image = serie.get('image', '')
                            
                            for season in episodes:
                                if not season.get('episodes'):
                                    continue
                                    
                                for episode in season['episodes']:
                                    if not episode.get('sources'):
                                        continue
                                        
                                    episode_url = episode['sources'][0].get('url', '')
                                    if episode_url:
                                        episode_name = f"{serie_name} - {episode.get('title', 'Bölüm')}"
                                        f.write(f'#EXTINF:-1 tvg-id="{episode.get("id", "")}" tvg-name="{episode_name}" tvg-logo="{serie_image}" group-title="DİZİLER - {category_name}",{episode_name}\n')
                                        f.write(f'#EXTVLCOPT:http-user-agent=googleusercontent\n')
                                        f.write(f'#EXTVLCOPT:http-referrer=https://twitter.com/\n')
                                        f.write(f"{episode_url}\n\n")
            
            print("\nPlaylist generation completed successfully!")

        if __name__ == "__main__":
            generate_m3u_playlist()
        EOF
        
        python generate_playlist.py
        
    - name: Commit and push changes
      if: success()
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add playlist.m3u
        git diff --quiet && git diff --staged --quiet || git commit -m "Update M3U playlist [auto]"
        git push
